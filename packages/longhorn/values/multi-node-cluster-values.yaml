# See the UDS RKE2 repository's documentation, `docs/ROOK-CEPH.md` for more details on values overrides

imagePullSecrets:
  - name: private-registry

toolbox:
  enabled: true
  # TODO: setup renovate
  image: ###ZARF_REGISTRY###/ironbank/opensource/ceph/ceph:v18.2.2

cephClusterSpec:
  mon:
    count: ###ZARF_VAR_REPLICAS###
    allowMultiplePerNode: true

  mgr:
    count: ###ZARF_VAR_REPLICAS###
    allowMultiplePerNode: true
    modules:
      - name: rook
        enabled: true

  cephVersion:
    # TODO: setup renovate
    image: ###ZARF_REGISTRY###/ironbank/opensource/ceph/ceph:v18.2.2
    allowUnsupported: true

  dashboard:
    enabled: true
    ssl: false

  monitoring:
    enabled: ###ZARF_VAR_ENABLE_MONITORING###
    rulesNamespace: rook-ceph
    createPrometheusRules: false

  network:
    # Use host networking to avoid CNI causing storage issues
    # Equivalent to legacy `hostNetwork: true`
    provider: host
    connections:
      encryption:
        enabled: true

  storage:
    useAllNodes: true
    useAllDevices: true
    devices:
      - name: ###ZARF_VAR_DEVICE_NAME###
    config:
      osdsPerDevice: "1"

cephBlockPools:
  - name: ceph-block
    spec:
      failureDomain: host
      replicated:
        size: ###ZARF_VAR_REPLICAS###
      storageClass:
        enabled: ###ZARF_VAR_ENABLE_CEPH_BLOCK_STORE###
        isDefault: ###ZARF_VAR_CEPH_BLOCK_STORE_AS_DEFAULT###

cephFileSystems:
  - name: ceph-filesystem
    spec:
      dataPools:
        - failureDomain: host
          replicated:
            size: ###ZARF_VAR_REPLICAS###
          compressionMode: none
      metadataPool:
        replicated:
          size: ###ZARF_VAR_REPLICAS###
      metadataServer:
        activeCount: ###ZARF_VAR_ACTIVE_METADATA_SERVERS###
        activeStandby: false
    storageClass:
      enabled: ###ZARF_VAR_ENABLE_CEPH_FILE_STORE###
      isDefault: ###ZARF_VAR_CEPH_FILE_STORE_AS_DEFAULT###

cephObjectStores:
  - name: ceph-objectstore
    spec:
      dataPools:
        replicated:
          size: ###ZARF_VAR_REPLICAS###
      metadataPool:
        replicated:
          size: ###ZARF_VAR_REPLICAS###
        failureDomain: host
      dataPool:
        failureDomain: host
      gateway:
        instances: 1
    storageClass:
      enabled: ###ZARF_VAR_ENABLE_CEPH_BLOCK_STORE###
      isDefault: ###ZARF_VAR_CEPH_OBJECT_STORE_AS_DEFAULT###
      parameters:
        region: ###ZARF_VAR_REGION###
