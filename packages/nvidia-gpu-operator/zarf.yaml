# TODO: renovate setup
# yaml-language-server: $schema=https://raw.githubusercontent.com/defenseunicorns/uds-cli/v0.10.4/zarf.schema.json

kind: ZarfPackageConfig
metadata:
  name: nvidia-gpu-operator
  description: "Zarf package of NVIDIA's GPU Operator"
  version: "###ZARF_PKG_TMPL_VERSION###"
  architecture: amd64

components:
  - name: node-feature-discovery
    required: true
    images:
      # gpu-operator pre-requisite via https://github.com/NVIDIA/gpu-operator/blob/main/deployments/gpu-operator/Chart.yaml
      - registry1.dso.mil/ironbank/opensource/nfd/node-feature-discovery:v0.15.4
    charts:
      - name: node-feature-discovery
        namespace: nvidia-gpu-operator
        url: https://kubernetes-sigs.github.io/node-feature-discovery/charts
        version: v0.15.4
        valuesFiles:
          - values/node-feature-discovery-values.yaml

  - name: nvidia-gpu-operator
    required: true
    images:
      - registry1.dso.mil/ironbank/opensource/nvidia/gpu-operator:v24.3.0
      - registry1.dso.mil/ironbank/opensource/nvidia/gpu-operator-validator:v24.3.0
      - registry1.dso.mil/ironbank/opensource/nvidia/k8s-device-plugin:v0.15.1-ubi8
      - registry1.dso.mil/ironbank/opensource/nvidia/cuda:12.4
    charts:
      - name: gpu-operator
        url: https://helm.ngc.nvidia.com/nvidia
        # TODO: renovate setup
        version: v24.3.0
        namespace: nvidia-gpu-operator
        valuesFiles:
          - "values/nvidia-gpu-operator-values.yaml"
    actions:
      onDeploy:
        after:
          # The following onDeploy actions are due to an upstream Registry1 issue: https://repo1.dso.mil/dsop/opensource/nvidia/gpu-operator/-/issues/11
          - cmd: |
              kubectl patch daemonset nvidia-operator-validator -n nvidia-gpu-operator --type='json' -p='[
                {"op": "add", "path": "/spec/template/spec/containers/0/securityContext/runAsUser", "value": 0}
              ]'
              kubectl patch daemonset nvidia-operator-validator -n nvidia-gpu-operator --type='json' -p='[
                {"op": "add", "path": "/spec/template/spec/initContainers/0/securityContext/runAsUser", "value": 0}
              ]'
              kubectl patch daemonset nvidia-operator-validator -n nvidia-gpu-operator --type='json' -p='[
                {"op": "add", "path": "/spec/template/spec/initContainers/1/securityContext/runAsUser", "value": 0}
              ]'
              kubectl patch daemonset nvidia-operator-validator -n nvidia-gpu-operator --type='json' -p='[
                {"op": "add", "path": "/spec/template/spec/initContainers/2/securityContext/runAsUser", "value": 0}
              ]'
              kubectl patch daemonset nvidia-operator-validator -n nvidia-gpu-operator --type='json' -p='[
                {"op": "add", "path": "/spec/template/spec/initContainers/3/securityContext/runAsUser", "value": 0}
              ]'
            description: "Patch securityContext in the nvidia-operator-validator"
            maxTotalSeconds: 60
          - cmd: |
              kubectl patch daemonset gpu-feature-discovery -n nvidia-gpu-operator --type='json' -p='[
                {"op": "add", "path": "/spec/template/spec/containers/0/securityContext/runAsUser", "value": 0}
              ]'
              kubectl patch daemonset gpu-feature-discovery -n nvidia-gpu-operator --type='json' -p='[
                {"op": "add", "path": "/spec/template/spec/initContainers/0/securityContext/runAsUser", "value": 0}
              ]'
            description: "Patch securityContext in the gpu-feature-discovery"
            maxTotalSeconds: 60
          - cmd: |
              kubectl patch daemonset nvidia-device-plugin-daemonset -n nvidia-gpu-operator --type='json' -p='[
                {"op": "add", "path": "/spec/template/spec/containers/0/securityContext/runAsUser", "value": 0}
              ]'
              kubectl patch daemonset nvidia-device-plugin-daemonset -n nvidia-gpu-operator --type='json' -p='[
                {"op": "add", "path": "/spec/template/spec/initContainers/0/securityContext/runAsUser", "value": 0}
              ]'
            description: "Patch securityContext in the nvidia-device-plugin-daemonset"
            maxTotalSeconds: 60
          # Validate that all components are back up and running after the patches
          - description: "Validate nvidia-operator-validator is up"
            wait:
              cluster:
                kind: Pod
                name: app=nvidia-operator-validator
                namespace: nvidia-gpu-operator
                condition: "'{.status.conditions[2].status}'=True"
            maxTotalSeconds: 300
          - description: "Validate gpu-feature-discovery is up"
            wait:
              cluster:
                kind: Pod
                name: app=gpu-feature-discovery
                namespace: nvidia-gpu-operator
                condition: "'{.status.conditions[2].status}'=True"
            maxTotalSeconds: 300
          - description: "Validate nvidia-device-plugin-daemonset is up"
            wait:
              cluster:
                kind: Pod
                name: app=nvidia-device-plugin-daemonset
                namespace: nvidia-gpu-operator
                condition: "'{.status.conditions[2].status}'=True"
            maxTotalSeconds: 300
        onFailure:
          - cmd: uds zarf tools kubectl describe nodes
            description: "Attempt to provide node data for debugging after a failed deployment"
